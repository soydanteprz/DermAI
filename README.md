# Proyecto: DetecciÃ³n de CÃ¡ncer en la Piel por ClasificaciÃ³n de ImÃ¡genes

Este proyecto tiene como objetivo detectar cÃ¡ncer en la piel a partir de imÃ¡genes de lesiones cutÃ¡neas utilizando tÃ©cnicas de clasificaciÃ³n de imÃ¡genes. Para ello, se utiliza un dataset disponible en Kaggle:  
ğŸ“ [Skin Cancer (PAD-UFES-20)](https://www.kaggle.com/datasets/mahdavi1202/skin-cancer)

## ğŸ“Š DescripciÃ³n del Dataset

El dataset contiene un total de **2,298 imÃ¡genes** correspondientes a **1,641 lesiones** de **1,373 pacientes**, abarcando **6 tipos diferentes de condiciones cutÃ¡neas**, divididas entre:

- **CÃ¡nceres de piel**:
    - BCC: Carcinoma Basocelular (Basal Cell Carcinoma)
    - SCC: Carcinoma de CÃ©lulas Escamosas (Squamous Cell Carcinoma)
    - MEL: Melanoma

- **Otras enfermedades cutÃ¡neas**:
    - ACK: Queratosis ActÃ­nica (Actinic Keratosis)
    - SEK: Queratosis Seborreica (Seborrheic Keratosis)
    - NEV: Nevus


### ğŸ“ Estructura de los datos

- El dataset original viene comprimido en un `.zip` que contiene:
    - Una carpeta con **todas las imÃ¡genes sin clasificar**.
    - Un archivo `.csv` con **metadatos y etiquetas diagnÃ³sticas**.

### ğŸ§¬ Atributos en los metadatos (CSV)

El CSV contiene **26 atributos** por cada muestra. Algunos de los mÃ¡s relevantes son:

- `patient_id`, `lesion_id`, `img_id`: identificadores Ãºnicos.
- `diagnostic`: etiqueta con el tipo de lesiÃ³n.
- `age`, `gender`, `region`: informaciÃ³n del paciente.
- Factores de riesgo como: `smoke`, `drink`, `pesticide`, `skin_cancer_history`, `cancer_history`, etc.
- CaracterÃ­sticas de la lesiÃ³n: `itch`, `grew`, `hurt`, `changed`, `bleed`, `elevation`, `diameter_1`, `diameter_2`.
- `biopsed`: indica si la muestra fue confirmada por biopsia.

Cerca del **58% de las muestras son biopsiadas** y confirmadas por expertos dermatÃ³logos.

---

## âš™ï¸ Preprocesamiento de Datos

Dado que las imÃ¡genes **no estaban organizadas en carpetas por tipo de cÃ¡ncer**, se desarrollÃ³ el script `utils.py` para **reorganizar las imÃ¡genes** en carpetas segÃºn su diagnÃ³stico.

1. Se lee el archivo `metadata.csv` para construir un **diccionario** con pares `lesion_id: diagnÃ³stico`.
2. Se procesan todas las imÃ¡genes, extrayendo el `lesion_id` a partir del nombre de archivo, cuyo formato es:
    ```
    PAT_[patient_id]_[lesion_id]_[img_id].png
    ```

Ejemplo: `PAT_9_17_80.png`  
â†’ `lesion_id = 17`  
â†’ `diagnÃ³stico = ACK`  
â†’ La imagen se mueve a la carpeta `/ACK`

3. Las imÃ¡genes se **reorganizan en carpetas**, una por cada diagnÃ³stico (`ACK`, `BCC`, `MEL`, `NEV`, `SEK`, `SCC`).

---

## ğŸ“ DivisiÃ³n del Dataset

Una vez reorganizadas las imÃ¡genes, se realiza la divisiÃ³n del dataset en conjuntos de entrenamiento, validaciÃ³n y prueba:

- `train`: 70% de las imÃ¡genes.
- `validation`: 10% de las imÃ¡genes.
- `test`: 20% de las imÃ¡genes.

Cada carpeta (`train`, `validation`, `test`) contiene subcarpetas por tipo de diagnÃ³stico.

La carpeta data contiene la siguiente estructura:

```
data/
â”œâ”€â”€ metadata.csv
â”œâ”€â”€ split_report.txt
â”œâ”€â”€ full_images
â”œâ”€â”€ organized_images
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ ACK/
â”‚   â”œâ”€â”€ BCC/
â”‚   â”œâ”€â”€ MEL/
â”‚   â”œâ”€â”€ NEV/
â”‚   â”œâ”€â”€ SEK/
â”‚   â””â”€â”€ SCC/
â”œâ”€â”€ validation/
â”‚   â”œâ”€â”€ ACK/
â”‚   â”œâ”€â”€ BCC/
â”‚   â”œâ”€â”€ MEL/
â”‚   â”œâ”€â”€ NEV/
â”‚   â”œâ”€â”€ SEK/
â”‚   â””â”€â”€ SCC/
â””â”€â”€ test/
    â”œâ”€â”€ ACK/
    â”œâ”€â”€ BCC/
    â”œâ”€â”€ MEL/
    â”œâ”€â”€ NEV/
    â”œâ”€â”€ SEK/
    â””â”€â”€ SCC/
```
### ğŸ“Š Reporte de DivisiÃ³n
El archivo `split_report.txt` contiene un resumen de la divisiÃ³n del dataset, mostrando el nÃºmero de imÃ¡genes por tipo de diagnÃ³stico en cada conjunto (train, validation, test).
La carpeta `full_images` contiene todas las imÃ¡genes originales sin clasificar, mientras que `organized_images` contiene las imÃ¡genes reorganizadas por diagnÃ³stico.
Despues las imÃ¡genes se dividen en conjuntos de entrenamiento, validaciÃ³n y prueba, asegurando que cada conjunto tenga una representaciÃ³n equitativa de cada tipo de diagnÃ³stico.

> âš ï¸ **Nota importante**  
En el GitHub solamente se puede encontrar dentro de la carpeta `data` el archivo `metadata.csv`, el archivo `split_report.txt` por razones de espacio, pero en el siguiente link a Drive se wncuentra el resto de los archivos:
[Google Drive](https://drive.google.com/drive/folders/1nR3f4mr7ylwR_OyzVkAkjps9zQubiuI6?usp=sharing)
>

## ğŸ§  Data Augmentation y Entrenamiento del Modelo

### ğŸ“ˆ Aumento de Datos

Para mejorar el rendimiento del modelo de clasificaciÃ³n, se aplicaron tÃ©cnicas de **data augmentation** utilizando el notebook [`data_augmentation.ipynb`](./data_augmentation.ipynb).  
En este script:

- Se genera un **diccionario anidado** que contiene la informaciÃ³n actual de cada carpeta (una por diagnÃ³stico) y la **cantidad de imÃ¡genes** disponibles.
- Se evalÃºa el **balance del dataset** para determinar quÃ© clases necesitan mayor augmentaciÃ³n.
- Se aplican transformaciones como rotaciones, zoom, flips horizontales y verticales, entre otras, para aumentar la diversidad del conjunto de datos de entrenamiento sin necesidad de recolectar mÃ¡s imÃ¡genes.

---

### ğŸ§ª Modelo de ClasificaciÃ³n CNN

El modelo se define y entrena en el notebook [`cnn_dermai.ipynb`](./cnn_dermai.ipynb), inspirado en el artÃ­culo cientÃ­fico:

> ğŸ“„ *Skin cancer classification using convolutional neural networks*  
> [IOP Science, 2020](https://iopscience.iop.org/article/10.1088/1757-899X/982/1/012005/pdf)

En este notebook:

- Se construye una arquitectura **CNN personalizada** basada en la propuesta del paper.
- Se entrena el modelo con el dataset de imÃ¡genes dermatolÃ³gicas reorganizado.
- Se utilizan tÃ©cnicas como:
  - NormalizaciÃ³n de imÃ¡genes.
  - Callbacks como `ModelCheckpoint` y `EarlyStopping`.
- Al finalizar el entrenamiento, se guarda el modelo entrenado en el archivo `modelo_dermai.h5`, para su uso posterior en inferencia o despliegue.

## âœ… Estado Actual

- âœ… Dataset descargado y explorado
- âœ… Script para organizaciÃ³n por diagnÃ³stico implementado
- âœ… DivisiÃ³n en conjuntos de datos completada
- âœ… Data augmentation aplicado
- âœ… Modelo CNN definido y entrenado (No es el definitivo, se puede mejorar)
- âœ… Modelo guardado en formato `.h5`

---

## ğŸ‘¤ Autor

- **Dante David PÃ©rez PÃ©rez A01709226**

Uso de Data augmentation para mejorar el rendimiento del modelo de clasificaciÃ³n de imÃ¡genes, el script data_augmentation.ipynb creamos un diccionario de diccionario donde tiene la informacion actual de cada carpeta y la cantidad de imagenes que tiene.

Despues en cnn_dermai.ipynb se crea el modelo basado en el papel Skin cancer classification https://iopscience.iop.org/article/10.1088/1757-899X/982/1/012005/pdf
y se entrena con el dataset de imagenes de cancer de piel, al final se guarda el modelo en un archivo .h5 para su uso posterior.




def create_model():
"""Create CNN model based on research paper architecture with Mac M3 Pro GPU optimization"""

    print("CREATING CNN MODEL")
    print("-" * 40)

    strategy = tf.distribute.get_strategy()

    with strategy.scope():
        model = models.Sequential([
            # Input layer - adjusted to 150x150 instead of 128x128 to match your dataset
            layers.Input(shape=(128, 128, 3), name='input_layer'),

            layers.Conv2D(16, (3, 3), padding='same', name='conv1'),
            layers.BatchNormalization(name='batchnorm1'),
            layers.ReLU(name='relu1'),
            layers.MaxPooling2D((2, 2), name='maxpool1'),
            layers.Dropout(0.2, name='dropout1'),

            # Second Convolution Block
            layers.Conv2D(32, (3, 3), padding='same', name='conv2'),
            layers.BatchNormalization(name='batchnorm2'),
            layers.ReLU(name='relu2'),
            layers.MaxPooling2D((2, 2), name='maxpool2'),
            layers.Dropout(0.2, name='dropout2'),

            # Third Convolution Block
            layers.Conv2D(64, (3, 3), padding='same', name='conv3'),
            layers.BatchNormalization(name='batchnorm3'),
            layers.ReLU(name='relu3'),
            layers.MaxPooling2D((2, 2), name='maxpool3'),
            layers.Dropout(0.3, name='dropout3'),

            # Bloque Convolucional 3 (nuevo)
            layers.Conv2D(128, (3, 3), padding='same'),
            layers.BatchNormalization(),
            layers.ReLU(),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.4),

            layers.Flatten(),
            layers.Dense(128, activation='relu'),  # Capa densa intermedia
            layers.Dropout(0.5),
            layers.Dense(6, activation='softmax')
        ])

        # Optimized learning rate for GPU training (matching paper style)
        initial_lr = 0.001

        # Compile model - using paper-style optimizer
        model.compile(
            loss='categorical_crossentropy',
            optimizer=optimizers.Adam(learning_rate=initial_lr),
            metrics=['accuracy']
        )

    print(f"ğŸ“Š Total parameters: {model.count_params():,}")
    print(f"ğŸ¯ Optimized for: {'Mac M3 Pro GPU' if gpu_available else 'CPU'}")
    print(f"ğŸ“ˆ Initial learning rate: {initial_lr}")

    # Display model summary
    model.summary()
    print()

    return model


Epoch 60/60
1/93 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5s 65ms/step - accuracy: 0.2500 - loss: 6.2239
Epoch 60: val_accuracy did not improve from 0.31250
93/93 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 47ms/step - accuracy: 0.2500 - loss: 6.2239 - val_accuracy: 0.2232 - val_loss: 6.0415 - learning_rate: 1.0000e-08
