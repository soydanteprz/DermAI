{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data augmentation",
   "id": "49e1ae244e6a8a69"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-22T23:54:45.353140Z",
     "start_time": "2025-05-22T23:54:13.132041Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "DATA AUGMENTATION SCRIPT\n",
    "========================\n",
    "Optimized for square images (1:1 aspect ratio)\n",
    "Creates balanced dataset with 500 samples per class\n",
    "\n",
    "Author: Based on image analysis showing perfect 1:1 ratio images\n",
    "Usage: python augmentation_script.py\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "\n",
    "# âœ… PERFECT! Your images are already 1:1 squares - force_square is optimal\n",
    "print(\"ğŸ¯ DATA AUGMENTATION FOR BALANCED DATASET\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Target: 500 samples per class\")\n",
    "print()\n",
    "\n",
    "# Define paths\n",
    "base_dir = os.path.join(os.getcwd(), 'data')\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "balanced_train_dir = os.path.join(base_dir, 'balanced_train')\n",
    "\n",
    "# Class-specific augmentation requirements - EXACT VALUES for target 400\n",
    "class_augmentation_info = {\n",
    "    'MEL': {'current': 43,  'target': 500, 'augment_ratio': 11.63, 'samples_needed': 457},  # +1063.0%\n",
    "    'SCC': {'current': 130, 'target': 500, 'augment_ratio': 3.85,  'samples_needed': 370},  # +284.6%\n",
    "    'SEK': {'current': 161, 'target': 500, 'augment_ratio': 3.11,  'samples_needed': 339},  # +210.6%\n",
    "    'NEV': {'current': 177, 'target': 500, 'augment_ratio': 2.82,  'samples_needed': 323},  # +182.5%\n",
    "    'BCC': {'current': 588, 'target': 500, 'downsample_ratio': 0.85, 'samples_to_remove': 88},   # -15.0%\n",
    "    'ACK': {'current': 506, 'target': 500, 'downsample_ratio': 0.99, 'samples_to_remove': 6}     # -1.2%\n",
    "}\n",
    "\n",
    "def count_images_per_class(directory):\n",
    "    \"\"\"Count images in each class folder\"\"\"\n",
    "    class_counts = {}\n",
    "    for class_name in os.listdir(directory):\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            image_count = len([f for f in os.listdir(class_path)\n",
    "                               if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "            class_counts[class_name] = image_count\n",
    "    return class_counts\n",
    "\n",
    "def get_augmentation_strategy(class_name):\n",
    "    \"\"\"Get optimized augmentation parameters for each class\"\"\"\n",
    "\n",
    "    if class_name == 'MEL':  # CRITICAL - needs 9.3x increase (357 new samples)\n",
    "        return ImageDataGenerator(\n",
    "            rotation_range=30,           # More rotation for critical class\n",
    "            width_shift_range=0.3,       # Increased shifts\n",
    "            height_shift_range=0.3,\n",
    "            shear_range=0.25,           # More shear transformation\n",
    "            zoom_range=0.3,             # More zoom variation\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,         # Safe for skin lesions\n",
    "            brightness_range=[0.7, 1.3], # Wider brightness range\n",
    "            channel_shift_range=0.2,    # Color channel shifts\n",
    "            fill_mode='nearest'\n",
    "        ), \"ğŸ”¥ AGGRESSIVE\"\n",
    "\n",
    "    elif class_name == 'SCC':  # HIGH - needs 3.08x increase (270 new samples)\n",
    "        return ImageDataGenerator(\n",
    "            rotation_range=25,\n",
    "            width_shift_range=0.25,\n",
    "            height_shift_range=0.25,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.25,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            brightness_range=[0.8, 1.2],\n",
    "            channel_shift_range=0.15,\n",
    "            fill_mode='nearest'\n",
    "        ), \"ğŸ”¥ HIGH\"\n",
    "\n",
    "    elif class_name == 'SEK':  # MODERATE - needs 2.48x increase (239 new samples)\n",
    "        return ImageDataGenerator(\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.15,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            brightness_range=[0.85, 1.15],\n",
    "            channel_shift_range=0.1,\n",
    "            fill_mode='nearest'\n",
    "        ), \"ğŸ”¶ MODERATE\"\n",
    "\n",
    "    elif class_name == 'NEV':  # MODERATE - needs 2.26x increase (223 new samples)\n",
    "        return ImageDataGenerator(\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.15,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            brightness_range=[0.85, 1.15],\n",
    "            fill_mode='nearest'\n",
    "        ), \"ğŸ”¶ MODERATE\"\n",
    "\n",
    "    else:  # Default for any other classes\n",
    "        return ImageDataGenerator(\n",
    "            rotation_range=15,\n",
    "            width_shift_range=0.15,\n",
    "            height_shift_range=0.15,\n",
    "            zoom_range=0.15,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "        ), \"âšª DEFAULT\"\n",
    "\n",
    "def generate_augmented_images(source_dir, target_dir, num_augmented, class_name):\n",
    "    \"\"\"Generate augmented images optimized for each class's needs\"\"\"\n",
    "\n",
    "    # Get optimized augmentation strategy for this class\n",
    "    datagen, strategy_name = get_augmentation_strategy(class_name)\n",
    "\n",
    "    # Get original images\n",
    "    image_files = [f for f in os.listdir(source_dir)\n",
    "                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    if not image_files:\n",
    "        print(f\"No images found in {source_dir}\")\n",
    "        return\n",
    "\n",
    "    generated_count = 0\n",
    "\n",
    "    print(f\"     Strategy: {strategy_name}\")\n",
    "    print(f\"     ğŸ“ Square input â†’ 150Ã—150 output (optimal for your data)\")\n",
    "    print(f\"     ğŸ¯ Generating {num_augmented} new samples...\")\n",
    "\n",
    "    while generated_count < num_augmented:\n",
    "        # Randomly select an original image\n",
    "        img_file = np.random.choice(image_files)\n",
    "        img_path = os.path.join(source_dir, img_file)\n",
    "\n",
    "        try:\n",
    "            # Load and resize - your images are already square so this is perfect!\n",
    "            img = load_img(img_path, target_size=(150, 150))  # Minimal distortion since input is square\n",
    "            img_array = img_to_array(img)\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "            # Generate augmented image\n",
    "            aug_iter = datagen.flow(img_array, batch_size=1)\n",
    "            aug_image = aug_iter[0][0]\n",
    "\n",
    "            # Convert back to PIL image and save\n",
    "            aug_image = array_to_img(aug_image)\n",
    "            aug_filename = f\"aug_{class_name}_{generated_count:04d}.png\"\n",
    "            aug_image.save(os.path.join(target_dir, aug_filename))\n",
    "\n",
    "            generated_count += 1\n",
    "\n",
    "            # Progress updates\n",
    "            if num_augmented >= 100 and generated_count % 50 == 0:\n",
    "                progress = (generated_count / num_augmented) * 100\n",
    "                print(f\"        ğŸ”„ Progress: {generated_count}/{num_augmented} ({progress:.1f}%)\")\n",
    "            elif num_augmented < 100 and generated_count % 25 == 0:\n",
    "                progress = (generated_count / num_augmented) * 100\n",
    "                print(f\"        ğŸ”„ Progress: {generated_count}/{num_augmented} ({progress:.1f}%)\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"        âš ï¸ Error processing {img_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"     âœ… COMPLETED: {num_augmented} augmented images for {class_name}\")\n",
    "\n",
    "def create_balanced_dataset():\n",
    "    \"\"\"Main function to create balanced dataset\"\"\"\n",
    "\n",
    "    print(\"ğŸ›¡ï¸  CREATING BALANCED DATASET\")\n",
    "    print(f\"     Source: {train_dir} (READ ONLY - never modified)\")\n",
    "    print(f\"     Target: {balanced_train_dir} (NEW DIRECTORY)\")\n",
    "    print()\n",
    "\n",
    "    # Verify source directory exists\n",
    "    if not os.path.exists(train_dir):\n",
    "        print(f\"âŒ ERROR: Source directory not found: {train_dir}\")\n",
    "        print(\"   Please check your data directory structure.\")\n",
    "        return False\n",
    "\n",
    "    # Remove existing balanced directory if it exists\n",
    "    if os.path.exists(balanced_train_dir):\n",
    "        print(f\"     ğŸ—‘ï¸ Removing existing: {balanced_train_dir}\")\n",
    "        shutil.rmtree(balanced_train_dir)\n",
    "\n",
    "    # Create new balanced train directory\n",
    "    os.makedirs(balanced_train_dir)\n",
    "    print(f\"     âœ… Created: {balanced_train_dir}\")\n",
    "    print()\n",
    "\n",
    "    # Get current counts from original directory (READ ONLY)\n",
    "    current_counts = count_images_per_class(train_dir)\n",
    "\n",
    "    if not current_counts:\n",
    "        print(\"âŒ ERROR: No class directories found in train directory\")\n",
    "        return False\n",
    "\n",
    "    total_original = sum(current_counts.values())\n",
    "\n",
    "    print(\"ğŸ“Š CURRENT CLASS DISTRIBUTION:\")\n",
    "    for class_name, count in current_counts.items():\n",
    "        info = class_augmentation_info.get(class_name, {})\n",
    "        if 'target' in info:\n",
    "            change = info['target'] - count\n",
    "            symbol = \"ğŸ”¬\" if change > 0 else \"ğŸ“‰\" if change < 0 else \"âœ…\"\n",
    "            print(f\"     {symbol} {class_name}: {count} â†’ {info['target']} ({change:+d})\")\n",
    "        else:\n",
    "            print(f\"     âšª {class_name}: {count} (unknown class)\")\n",
    "    print(f\"     ğŸ“Š TOTAL ORIGINAL: {total_original} images\")\n",
    "    print()\n",
    "\n",
    "    # Process each class\n",
    "    for class_name in current_counts.keys():\n",
    "        class_info = class_augmentation_info.get(class_name, {})\n",
    "        original_class_dir = os.path.join(train_dir, class_name)  # SOURCE (read-only)\n",
    "        balanced_class_dir = os.path.join(balanced_train_dir, class_name)  # TARGET (new)\n",
    "        os.makedirs(balanced_class_dir)\n",
    "\n",
    "        # Get all image files from ORIGINAL directory\n",
    "        image_files = [f for f in os.listdir(original_class_dir)\n",
    "                       if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "        if not image_files:\n",
    "            print(f\"âš ï¸ WARNING: No images found in {class_name} directory\")\n",
    "            continue\n",
    "\n",
    "        if 'samples_needed' in class_info:  # Classes needing augmentation\n",
    "            print(f\"ğŸ”¬ AUGMENTING {class_name}:\")\n",
    "            print(f\"     Current: {current_counts[class_name]} â†’ Target: {class_info['target']}\")\n",
    "            print(f\"     Multiplication factor: {class_info['augment_ratio']:.2f}x\")\n",
    "            print(f\"     New samples to generate: {class_info['samples_needed']}\")\n",
    "\n",
    "            # COPY (not move) original images to new directory\n",
    "            copied_count = 0\n",
    "            for img_file in image_files:\n",
    "                try:\n",
    "                    shutil.copy2(os.path.join(original_class_dir, img_file),\n",
    "                                 os.path.join(balanced_class_dir, img_file))\n",
    "                    copied_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"        âš ï¸ Error copying {img_file}: {e}\")\n",
    "\n",
    "            print(f\"     âœ… Copied {copied_count} original images\")\n",
    "\n",
    "            # Generate augmented images in new directory\n",
    "            generate_augmented_images(original_class_dir, balanced_class_dir,\n",
    "                                      class_info['samples_needed'], class_name)\n",
    "\n",
    "        elif 'samples_to_remove' in class_info:  # Classes needing downsampling\n",
    "            print(f\"ğŸ“‰ DOWNSAMPLING {class_name}:\")\n",
    "            print(f\"     Current: {current_counts[class_name]} â†’ Target: {class_info['target']}\")\n",
    "            print(f\"     Keep ratio: {class_info['downsample_ratio']:.2f}x\")\n",
    "            print(f\"     Samples to remove: {class_info['samples_to_remove']}\")\n",
    "\n",
    "            # Randomly select images to keep (COPY, don't modify original)\n",
    "            np.random.seed(42)  # For reproducible results\n",
    "            np.random.shuffle(image_files)\n",
    "            selected_files = image_files[:class_info['target']]\n",
    "\n",
    "            copied_count = 0\n",
    "            for img_file in selected_files:\n",
    "                try:\n",
    "                    shutil.copy2(os.path.join(original_class_dir, img_file),\n",
    "                                 os.path.join(balanced_class_dir, img_file))\n",
    "                    copied_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"        âš ï¸ Error copying {img_file}: {e}\")\n",
    "\n",
    "            print(f\"     âœ… Copied {copied_count} selected images\")\n",
    "\n",
    "        else:\n",
    "            print(f\"âšª UNKNOWN CLASS {class_name}: Copying all images as-is\")\n",
    "            for img_file in image_files:\n",
    "                shutil.copy2(os.path.join(original_class_dir, img_file),\n",
    "                             os.path.join(balanced_class_dir, img_file))\n",
    "\n",
    "        print()\n",
    "\n",
    "    return True\n",
    "\n",
    "def verify_balanced_dataset():\n",
    "    \"\"\"Verify the balanced dataset was created correctly\"\"\"\n",
    "\n",
    "    print(\"ğŸ” FINAL VERIFICATION:\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    if not os.path.exists(balanced_train_dir):\n",
    "        print(\"âŒ ERROR: Balanced directory was not created\")\n",
    "        return False\n",
    "\n",
    "    # Get final counts\n",
    "    final_counts = count_images_per_class(balanced_train_dir)\n",
    "    total_balanced = sum(final_counts.values())\n",
    "\n",
    "    print(\"âœ… BALANCED DATASET VERIFICATION:\")\n",
    "\n",
    "    all_perfect = True\n",
    "    for class_name, count in final_counts.items():\n",
    "        target = class_augmentation_info.get(class_name, {}).get('target', count)\n",
    "        status = \"âœ…\" if count == target else \"âš ï¸\"\n",
    "        if count != target:\n",
    "            all_perfect = False\n",
    "        print(f\"     {status} {class_name}: {count} samples (target: {target})\")\n",
    "\n",
    "    print(f\"\\nğŸ“Š SUMMARY:\")\n",
    "    original_counts = count_images_per_class(train_dir)\n",
    "    total_original = sum(original_counts.values())\n",
    "\n",
    "    print(f\"     ğŸ“ˆ Original total: {total_original} images\")\n",
    "    print(f\"     ğŸ“ˆ Balanced total: {total_balanced} images\")\n",
    "    print(f\"     ğŸ“ˆ Net change: {'+' if total_balanced > total_original else ''}{total_balanced - total_original} images\")\n",
    "    print(f\"     ğŸ“ˆ Classes: {len(final_counts)} classes\")\n",
    "    print(f\"     ğŸ“ˆ Target per class: 400 images\")\n",
    "\n",
    "    if all_perfect:\n",
    "        print(f\"\\nğŸ¯ PERFECT BALANCE ACHIEVED! âœ…\")\n",
    "        print(f\"     All classes have exactly 400 samples\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ Minor discrepancies detected\")\n",
    "        print(f\"     Check individual class counts above\")\n",
    "\n",
    "    print(f\"\\nğŸ›¡ï¸ SAFETY CONFIRMATION:\")\n",
    "    print(f\"     âœ… Original data preserved at: {train_dir}\")\n",
    "    print(f\"     âœ… Balanced data created at: {balanced_train_dir}\")\n",
    "    print(f\"     âœ… All images resized to optimal 150Ã—150 format\")\n",
    "\n",
    "    return all_perfect\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "\n",
    "    print(\"ğŸš€ STARTING DATA AUGMENTATION PROCESS...\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Create balanced dataset\n",
    "    success = create_balanced_dataset()\n",
    "\n",
    "    if not success:\n",
    "        print(\"âŒ AUGMENTATION FAILED\")\n",
    "        return\n",
    "\n",
    "    # Verify results\n",
    "    verify_balanced_dataset()\n",
    "\n",
    "    print(\"\\nğŸ‰ DATA AUGMENTATION COMPLETED!\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"ğŸ“ Your balanced dataset is ready for training!\")\n",
    "    print(f\"ğŸ“ Location: {balanced_train_dir}\")\n",
    "    print(\"ğŸš€ Next step: Run the model training script\")\n",
    "    print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ DATA AUGMENTATION FOR BALANCED DATASET\n",
      "======================================================================\n",
      "Target: 500 samples per class\n",
      "\n",
      "ğŸš€ STARTING DATA AUGMENTATION PROCESS...\n",
      "======================================================================\n",
      "ğŸ›¡ï¸  CREATING BALANCED DATASET\n",
      "     Source: /Users/daperez/Documents/ProjectsSW/DermAI/data/train (READ ONLY - never modified)\n",
      "     Target: /Users/daperez/Documents/ProjectsSW/DermAI/data/balanced_train (NEW DIRECTORY)\n",
      "\n",
      "     âœ… Created: /Users/daperez/Documents/ProjectsSW/DermAI/data/balanced_train\n",
      "\n",
      "ğŸ“Š CURRENT CLASS DISTRIBUTION:\n",
      "     ğŸ”¬ SEK: 161 â†’ 500 (+339)\n",
      "     ğŸ“‰ BCC: 588 â†’ 500 (-88)\n",
      "     ğŸ”¬ NEV: 177 â†’ 500 (+323)\n",
      "     ğŸ”¬ SCC: 130 â†’ 500 (+370)\n",
      "     ğŸ”¬ MEL: 43 â†’ 500 (+457)\n",
      "     ğŸ“‰ ACK: 506 â†’ 500 (-6)\n",
      "     ğŸ“Š TOTAL ORIGINAL: 1605 images\n",
      "\n",
      "ğŸ”¬ AUGMENTING SEK:\n",
      "     Current: 161 â†’ Target: 500\n",
      "     Multiplication factor: 3.11x\n",
      "     New samples to generate: 339\n",
      "     âœ… Copied 161 original images\n",
      "     Strategy: ğŸ”¶ MODERATE\n",
      "     ğŸ“ Square input â†’ 150Ã—150 output (optimal for your data)\n",
      "     ğŸ¯ Generating 339 new samples...\n",
      "        ğŸ”„ Progress: 50/339 (14.7%)\n",
      "        ğŸ”„ Progress: 100/339 (29.5%)\n",
      "        ğŸ”„ Progress: 150/339 (44.2%)\n",
      "        ğŸ”„ Progress: 200/339 (59.0%)\n",
      "        ğŸ”„ Progress: 250/339 (73.7%)\n",
      "        ğŸ”„ Progress: 300/339 (88.5%)\n",
      "     âœ… COMPLETED: 339 augmented images for SEK\n",
      "\n",
      "ğŸ“‰ DOWNSAMPLING BCC:\n",
      "     Current: 588 â†’ Target: 500\n",
      "     Keep ratio: 0.85x\n",
      "     Samples to remove: 88\n",
      "     âœ… Copied 500 selected images\n",
      "\n",
      "ğŸ”¬ AUGMENTING NEV:\n",
      "     Current: 177 â†’ Target: 500\n",
      "     Multiplication factor: 2.82x\n",
      "     New samples to generate: 323\n",
      "     âœ… Copied 177 original images\n",
      "     Strategy: ğŸ”¶ MODERATE\n",
      "     ğŸ“ Square input â†’ 150Ã—150 output (optimal for your data)\n",
      "     ğŸ¯ Generating 323 new samples...\n",
      "        ğŸ”„ Progress: 50/323 (15.5%)\n",
      "        ğŸ”„ Progress: 100/323 (31.0%)\n",
      "        ğŸ”„ Progress: 150/323 (46.4%)\n",
      "        ğŸ”„ Progress: 200/323 (61.9%)\n",
      "        ğŸ”„ Progress: 250/323 (77.4%)\n",
      "        ğŸ”„ Progress: 300/323 (92.9%)\n",
      "     âœ… COMPLETED: 323 augmented images for NEV\n",
      "\n",
      "ğŸ”¬ AUGMENTING SCC:\n",
      "     Current: 130 â†’ Target: 500\n",
      "     Multiplication factor: 3.85x\n",
      "     New samples to generate: 370\n",
      "     âœ… Copied 130 original images\n",
      "     Strategy: ğŸ”¥ HIGH\n",
      "     ğŸ“ Square input â†’ 150Ã—150 output (optimal for your data)\n",
      "     ğŸ¯ Generating 370 new samples...\n",
      "        ğŸ”„ Progress: 50/370 (13.5%)\n",
      "        ğŸ”„ Progress: 100/370 (27.0%)\n",
      "        ğŸ”„ Progress: 150/370 (40.5%)\n",
      "        ğŸ”„ Progress: 200/370 (54.1%)\n",
      "        ğŸ”„ Progress: 250/370 (67.6%)\n",
      "        ğŸ”„ Progress: 300/370 (81.1%)\n",
      "        ğŸ”„ Progress: 350/370 (94.6%)\n",
      "     âœ… COMPLETED: 370 augmented images for SCC\n",
      "\n",
      "ğŸ”¬ AUGMENTING MEL:\n",
      "     Current: 43 â†’ Target: 500\n",
      "     Multiplication factor: 11.63x\n",
      "     New samples to generate: 457\n",
      "     âœ… Copied 43 original images\n",
      "     Strategy: ğŸ”¥ AGGRESSIVE\n",
      "     ğŸ“ Square input â†’ 150Ã—150 output (optimal for your data)\n",
      "     ğŸ¯ Generating 457 new samples...\n",
      "        ğŸ”„ Progress: 50/457 (10.9%)\n",
      "        ğŸ”„ Progress: 100/457 (21.9%)\n",
      "        ğŸ”„ Progress: 150/457 (32.8%)\n",
      "        ğŸ”„ Progress: 200/457 (43.8%)\n",
      "        ğŸ”„ Progress: 250/457 (54.7%)\n",
      "        ğŸ”„ Progress: 300/457 (65.6%)\n",
      "        ğŸ”„ Progress: 350/457 (76.6%)\n",
      "        ğŸ”„ Progress: 400/457 (87.5%)\n",
      "        ğŸ”„ Progress: 450/457 (98.5%)\n",
      "     âœ… COMPLETED: 457 augmented images for MEL\n",
      "\n",
      "ğŸ“‰ DOWNSAMPLING ACK:\n",
      "     Current: 506 â†’ Target: 500\n",
      "     Keep ratio: 0.99x\n",
      "     Samples to remove: 6\n",
      "     âœ… Copied 500 selected images\n",
      "\n",
      "ğŸ” FINAL VERIFICATION:\n",
      "======================================================================\n",
      "âœ… BALANCED DATASET VERIFICATION:\n",
      "     âœ… SEK: 500 samples (target: 500)\n",
      "     âœ… BCC: 500 samples (target: 500)\n",
      "     âœ… NEV: 500 samples (target: 500)\n",
      "     âœ… SCC: 500 samples (target: 500)\n",
      "     âœ… MEL: 500 samples (target: 500)\n",
      "     âœ… ACK: 500 samples (target: 500)\n",
      "\n",
      "ğŸ“Š SUMMARY:\n",
      "     ğŸ“ˆ Original total: 1605 images\n",
      "     ğŸ“ˆ Balanced total: 3000 images\n",
      "     ğŸ“ˆ Net change: +1395 images\n",
      "     ğŸ“ˆ Classes: 6 classes\n",
      "     ğŸ“ˆ Target per class: 400 images\n",
      "\n",
      "ğŸ¯ PERFECT BALANCE ACHIEVED! âœ…\n",
      "     All classes have exactly 400 samples\n",
      "\n",
      "ğŸ›¡ï¸ SAFETY CONFIRMATION:\n",
      "     âœ… Original data preserved at: /Users/daperez/Documents/ProjectsSW/DermAI/data/train\n",
      "     âœ… Balanced data created at: /Users/daperez/Documents/ProjectsSW/DermAI/data/balanced_train\n",
      "     âœ… All images resized to optimal 150Ã—150 format\n",
      "\n",
      "ğŸ‰ DATA AUGMENTATION COMPLETED!\n",
      "======================================================================\n",
      "ğŸ“ Your balanced dataset is ready for training!\n",
      "ğŸ“ Location: /Users/daperez/Documents/ProjectsSW/DermAI/data/balanced_train\n",
      "ğŸš€ Next step: Run the model training script\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
